# bot_main4.py
# ëª©ì : GGUF(ë² ì´ìŠ¤) + GGUF-LoRA(í–‰ë™ê²°ì •)ë¡œ ë„êµ¬ ì„ íƒë§Œ ë¡œì»¬ LLaMAê°€ í•˜ê³ ,
#      ì‹¤í–‰( URLBERT / RAG / Chat )ì€ ê¸°ì¡´ íŒŒì´í”„ë¼ì¸(Gemini/URLBERT/RAG)ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©.
#      + ëª¨ë¸ì˜ ì˜ëª»ëœ íŒë‹¨ì„ ë³´ì •í•˜ëŠ” ì•ˆì „ì¥ì¹˜(Sanity Check) ì¶”ê°€

import os
import sys
import re
import warnings

# 0) í™˜ê²½/ê²½ê³ 
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")
warnings.filterwarnings("ignore", category=FutureWarning, module="huggingface_hub.file_download")

# 1) ì™¸ë¶€/í”„ë¡œì íŠ¸ ì˜ì¡´ì„±
from langchain.agents import Tool
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory

load_dotenv('api.env')

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

urlbert_base = os.path.join(project_root, 'urlbert', 'urlbert2')
if urlbert_base not in sys.path:
    sys.path.insert(0, urlbert_base)

from bot.tools.urlbert_tool import load_urlbert_tool
from bot.tools.rag_tools import load_rag_tool, build_rag_index_from_jsonl
from urlbert.urlbert2.core.model_loader import GLOBAL_MODEL, GLOBAL_TOKENIZER
from bot.feature_extractor import build_raw_features, summarize_features_for_explanation

# 2) Gemini (ì½˜í…ì¸  ìƒì„±/ìš”ì•½ ë“± ê¸°ì¡´ ì—­í• ) ì´ˆê¸°í™”
if "GOOGLE_API_KEY" not in os.environ:
    raise ValueError("í™˜ê²½ ë³€ìˆ˜ì— 'GOOGLE_API_KEY'ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

gemini = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.01)

def chat_fn(query: str) -> str:
    try:
        raw = gemini.invoke(query).content
        return raw.strip()
    except Exception as e:
        print(f"Gemini API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."

chat_tool = Tool(
    name="Chat",
    func=chat_fn,
    description="ì¼ë°˜ ëŒ€í™” ë° ê°„ë‹¨í•œ ì •ë³´ ë‹µë³€ìš©"
)

# 3) ë³´ì•ˆ íˆ´(URLBERT, RAG) ì´ˆê¸°í™”
try:
    url_tool = load_urlbert_tool(GLOBAL_MODEL, GLOBAL_TOKENIZER)
except Exception as e:
    url_tool = Tool(
        name="URL_Analyzer",
        func=lambda x, _e=str(e): f"URL ë¶„ì„ íˆ´ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {_e}",
        description="URL ì•ˆì „/ìœ„í—˜ íŒë‹¨"
    )

RAG_INDEX_DIR = os.path.join(project_root, 'security_faiss_index')
RAG_DATA_PATH = os.path.join(project_root, 'data', 'rag_dataset.jsonl')
if not os.path.exists(RAG_INDEX_DIR):
    if os.path.exists(RAG_DATA_PATH):
        print(f"ğŸ”§ RAG ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤: {RAG_DATA_PATH} -> {RAG_INDEX_DIR}")
        build_rag_index_from_jsonl(RAG_DATA_PATH, RAG_INDEX_DIR)
    else:
        print(f"âš ï¸ RAG ë°ì´í„° íŒŒì¼({RAG_DATA_PATH})ì´ ì—†ì–´ RAG ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

try:
    rag_tool = load_rag_tool(RAG_INDEX_DIR, gemini)
except Exception as e:
    print(f"âŒ RAG íˆ´ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    rag_tool = Tool(
        name="RAG",
        func=lambda q: "RAG íˆ´ ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        description="ë³´ì•ˆ ë¬¸ì„œ ê²€ìƒ‰ (í˜„ì¬ ë¹„í™œì„±í™”ë¨)"
    )

# 4) ìƒì„¸ URL ì„¤ëª… í”„ë¡¬í”„íŠ¸(ê¸°ì¡´ ìœ ì§€)
URL_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ URL ë³´ì•ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ í•¨ê»˜ ì œê³µëœ URL ë¶„ì„ ê²°ê³¼ ë° ì„¸ë¶€ íŠ¹ì§• ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ,
ì™œ í•´ë‹¹ URLì´ ìœ„í—˜í•˜ê±°ë‚˜ ì•ˆì „í•œì§€ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_query}

[URL-BERT 1ì°¨ ë¶„ì„ ê²°ê³¼]
{bert_result}

[ì„¸ë¶€ íŠ¹ì§• ë°ì´í„°]
{feature_details}

[ë‹µë³€ ê°€ì´ë“œ]
1. URL-BERTì˜ ìµœì¢… íŒì •(ì •ìƒ/ì•…ì„±)ì„ ë¨¼ì € ëª…í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”.
2. 'ì„¸ë¶€ íŠ¹ì§• ë°ì´í„°'ë¥¼ ê·¼ê±°ë¡œ ë“¤ì–´ ì™œ ê·¸ë ‡ê²Œ íŒë‹¨í–ˆëŠ”ì§€ 2~3ê°€ì§€ í•µì‹¬ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.
3. ì‚¬ìš©ìê°€ ì–´ë–»ê²Œ í–‰ë™í•´ì•¼ í• ì§€ ê°„ë‹¨í•œ ì¡°ì¹˜ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.
4. ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ ëŒ€í™”ì²´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

[ìµœì¢… ë‹µë³€]
"""
url_prompt = PromptTemplate.from_template(URL_PROMPT_TEMPLATE)

# 5) ë©”ëª¨ë¦¬
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# 6) llama-cpp ê¸°ë°˜ "í–‰ë™ ê²°ì •ê¸°" ì´ˆê¸°í™” (GGUF + GGUF-LoRA)
from llama_cpp import Llama

LLM_GGUF = os.getenv(
    "LLM_GGUF",
    "/home/injeolmi/project/models/gguf/llama-3-Korean-Bllossom-8B-Q4_K_M.gguf"
)
LORA_GGUF = os.getenv(
    "LORA_GGUF",
    "/home/injeolmi/project/models/gguf/bllossom_agent_lora3.gguf"
)

try:
    llm_decider = Llama(
        model_path=LLM_GGUF,
        lora_path=LORA_GGUF,
        n_ctx=4096,
        n_threads=int(os.getenv("LLAMA_THREADS", "8")),
        n_gpu_layers=0,
        chat_format="llama-3",
        verbose=True
    )
    print(f"âœ… llama.cpp(ê²°ì •ê¸°) loaded: base={LLM_GGUF}, lora={LORA_GGUF}")
except Exception as e:
    llm_decider = None
    print(f"âŒ llama.cpp ë¡œë“œ ì‹¤íŒ¨: {e}  (ê·œì¹™ê¸°ë°˜ í´ë°± ì‚¬ìš©)")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7) í–‰ë™ ê²°ì • ìœ í‹¸
STOP_WORDS = ["\n\n", "\nAction Result", "\nAction Logic", "\nAction Reference", "assistant\n", "assistant"]
VALID_ACTIONS = {"URL_SIMPLE", "URL_DETAILED", "RAG", "CHAT"}
ACT_PAT = re.compile(r"Action:\s*(?P<act>[A-Za-z_]+)\s*\nAction Input:\s*(?P<input>.+)", re.S)
URL_PAT = re.compile(r'(https?://\S+|(?:[a-zA-Z0-9-]+\.)+[a-zA-Z]{2,}\S*)', re.I)


def _truncate_on_stops(s: str) -> str:
    cut = len(s)
    for w in STOP_WORDS:
        i = s.find(w)
        if i != -1:
            cut = min(cut, i)
    return s[:cut]

def _first_url(text: str):
    m = URL_PAT.search(text or "")
    return m.group(0) if m else None

def decide_action_with_llm(user_query: str):
    sys_prompt = (
        "ë„ˆëŠ” ë³´ì•ˆ ë¶„ì„ ì±—ë´‡ì´ì•¼. ì§ˆë¬¸ì— ë§ì¶° ì˜¤ì§ ë‹¤ìŒ í˜•ì‹ë§Œ ì¶œë ¥í•´.\n"
        "Action: <URL_SIMPLE|URL_DETAILED|RAG|CHAT>\n"
        "Action Input: <í…ìŠ¤íŠ¸>"
    )

    if llm_decider is not None:
        try:
            out = llm_decider.create_chat_completion(
                messages=[
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": user_query},
                ],
                temperature=0.0, top_p=1.0, repeat_penalty=1.2, max_tokens=128
            )
            raw = out["choices"][0]["message"]["content"]
            raw = _truncate_on_stops(raw)
            m = ACT_PAT.search(raw)
            if m and m.group("act") in VALID_ACTIONS:
                action = m.group("act").strip()
                action_input = _truncate_on_stops(m.group("input").strip()).splitlines()[0].strip()
                
                if action in ["URL_SIMPLE", "URL_DETAILED"]:
                    url = _first_url(action_input) or _first_url(user_query)
                    action_input = url if url else user_query
                return action, action_input, raw
        except Exception as e:
            print(f"LLM ê²°ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤.")

    why_tokens = ["ì™œ", "ì´ìœ ", "ê·¼ê±°", "ìì„¸íˆ", "ì„¤ëª…", "ì–´ë–¤ ì ", "íŠ¹ì§•", "ì›ë¦¬", "íŒŒí—¤ì³ì¤˜", "ê¸°ìˆ ì ìœ¼ë¡œ"]
    url = _first_url(user_query)
    if url:
        action = "URL_DETAILED" if any(k in user_query for k in why_tokens) else "URL_SIMPLE"
        action_input = url
    else:
        chat_starters = ["ì•ˆë…•", "í•˜ì´", "ã…ã…‡", "ê³ ë§ˆì›Œ", "ê°ì‚¬", "ìˆ˜ê³ ", "ìš”ì¦˜", "ë­í•´", "ã…‹ã…‹ã…‹", "ë°°ê³ í”„ë‹¤"]
        action = "CHAT" if any(starter in user_query for starter in chat_starters) else "RAG"
        action_input = user_query
        
    return action, action_input, "(fallback-rules)"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8) ë³´ì¡° í•¨ìˆ˜
def _infer_verdict_from_text(bert_text: str) -> str:
    t = (bert_text or "").lower()
    bad = ["malicious", "phishing", "suspicious", "ì•…ì„±", "ìœ„í—˜", "ìœ í•´"]
    good = ["benign", "legitimate", "safe", "ì •ìƒ", "ì•ˆì „"]
    if any(tok in t for tok in bad) and not any(tok in t for tok in good):
        return "ì•…ì„±"
    if any(tok in t for tok in good) and not any(tok in t for tok in bad):
        return "ì •ìƒ"
    return "ì •ìƒ"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 9) ìµœì¢… ë¼ìš°íŒ…
def get_chatbot_response(user_text: str) -> dict:
    text = user_text.strip()

    # â‘  LLaMAì—ê²Œ ë„êµ¬ ì„ íƒì„ ë§¡ê¸´ë‹¤
    action, action_input, raw_llm = decide_action_with_llm(text)
    
    url_in_text = _first_url(text)
    if action in ["URL_SIMPLE", "URL_DETAILED"] and not url_in_text:
        print(f"âš ï¸ ëª¨ë¸ì´ URL ì—†ëŠ” ì§ˆë¬¸ì— '{action}'ì„ ì„ íƒí•˜ì—¬ 'RAG'ë¡œ ê°•ì œ ì¡°ì •í•©ë‹ˆë‹¤.")
        action = "RAG"
        action_input = text

    response_data = {
        "action": action, 
        "action_input": action_input, 
        "raw_llm": raw_llm
    }

    # â‘¡ ì‹¤í–‰ ë¶„ê¸° (ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ try-exceptë¡œ ê°ìŒˆ)
    try:
        if action == "URL_SIMPLE":
            bert_result_text = url_tool.func(action_input)
            response_data.update({"answer": bert_result_text, "mode": "url_analysis_simple", "url": action_input})

        elif action == "URL_DETAILED":
            bert_result_text = url_tool.func(action_input)
            raw_features_df = build_raw_features(action_input)
            
            if not raw_features_df.empty:
                verdict = _infer_verdict_from_text(bert_result_text)
                reasons = summarize_features_for_explanation(raw_features_df, verdict, top_k=3)
                feature_details = "\n".join(f"- {r}" for r in reasons) if reasons else "ì„¸ë¶€ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            else:
                feature_details = "ì„¸ë¶€ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

            final_prompt = url_prompt.format(
                user_query=text,
                bert_result=bert_result_text,
                feature_details=feature_details
            )
            final_answer = chat_tool.func(final_prompt)
            response_data.update({"answer": final_answer, "mode": "url_analysis_detailed", "url": action_input})

        elif action == "RAG":
            rag_out = rag_tool.func(action_input)
            rag_answer = rag_out.get("answer", "ì£„ì†¡í•©ë‹ˆë‹¤, ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            sources = rag_out.get("sources", [])
            response_data.update({"answer": rag_answer, "mode": "rag", "sources": sources[:5]})

        elif action == "CHAT":
            chat_answer = chat_tool.func(action_input)
            response_data.update({"answer": chat_answer, "mode": "chat"})
        
        else: # ì˜ˆì™¸ì ì¸ Action ê²°ì • ì‹œ
            chat_answer = chat_tool.func(text)
            response_data.update({"answer": chat_answer, "mode": "chat", "action": "CHAT (Fallback)"})

    except Exception as e:
        print(f"ğŸš¨ [ERROR] Action '{action}' ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        response_data.update({"answer": "ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì‹œê² ì–´ìš”?", "mode": "error"})

    return response_data

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 10) ì¸í„°ë™í‹°ë¸Œ ë£¨í”„
if __name__ == '__main__':
    print("--- ì±—ë´‡ ì‹œì‘ (ì¢…ë£Œ: 'ì¢…ë£Œ') ---")
    while True:
        try:
            text = input("You â–¶ ").strip()
        except (EOFError, KeyboardInterrupt):
            break

        if text.lower() in {"ì¢…ë£Œ", "exit"}:
            break
        if not text:
            continue

        response = get_chatbot_response(text)
        
        print(f"--- [Debug Info] ---")
        print(f"Action: {response.get('action')}")
        print(f"Action Input: {response.get('action_input')}")
        print(f"--------------------")
        
        answer = response.get("answer")
        mode = response.get("mode")

        memory.save_context({"input": text}, {"output": answer})

        if mode == "rag":
            print("ğŸ” [RAG ë¬¸ì„œ ê¸°ë°˜ ì‘ë‹µ]")
        elif mode == "chat":
            print("ğŸ’¬ [ì¼ë°˜ Chat ì‘ë‹µ]")
        elif mode == "url_analysis_detailed":
            if response.get("url"):
                print(f"   ëŒ€ìƒ: {response['url']}")
        elif mode == "url_analysis_simple":
            if response.get("url"):
                print(f"   ëŒ€ìƒ: {response['url']}")

        print(f"Bot â–¶ {answer}")

        if response.get("sources"):
            print("ğŸ“š [ì¶œì²˜]")
            for s in response["sources"]:
                print(" -", s)
        
        print("\n")