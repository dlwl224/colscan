# bot_main4.py
# ëª©ì : íŒŒì¸íŠœë‹ëœ LLaMAë¥¼ "í–‰ë™ ê²°ì •ê¸°"ë¡œ ë¶™ì´ê³ , ì‹¤í–‰( URLBERT / RAG / Chat )ì€ ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
import os
import sys
import re
import warnings
import torch  
# 0) í™˜ê²½/ê²½ê³ 
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")
warnings.filterwarnings("ignore", category=FutureWarning, module="huggingface_hub.file_download")

# 1) ì™¸ë¶€/í”„ë¡œì íŠ¸ ì˜ì¡´ì„±
from langchain.agents import Tool
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory

load_dotenv('api.env')

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

urlbert_base = os.path.join(project_root, 'urlbert', 'urlbert2')
if urlbert_base not in sys.path:
    sys.path.insert(0, urlbert_base)

from bot.tools.urlbert_tool import load_urlbert_tool
from bot.tools.rag_tools import load_rag_tool, build_rag_index_from_jsonl
from urlbert.urlbert2.core.model_loader import GLOBAL_MODEL, GLOBAL_TOKENIZER
from bot.feature_extractor import build_raw_features, summarize_features_for_explanation

# 2) Gemini (ì½˜í…ì¸  ìƒì„±/ìš”ì•½ ë“± ê¸°ì¡´ ì—­í• ) ì´ˆê¸°í™”
if "GOOGLE_API_KEY" not in os.environ:
    raise ValueError("í™˜ê²½ ë³€ìˆ˜ì— 'GOOGLE_API_KEY'ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

gemini = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.01)

def chat_fn(query: str) -> str:
    raw = gemini.invoke(query).content
    return raw.strip()

chat_tool = Tool(
    name="Chat",
    func=chat_fn,
    description="ì¼ë°˜ ëŒ€í™” ë° ê°„ë‹¨í•œ ì •ë³´ ë‹µë³€ìš©"
)

# 3) ë³´ì•ˆ íˆ´(URLBERT, RAG) ì´ˆê¸°í™”
try:
    url_tool = load_urlbert_tool(GLOBAL_MODEL, GLOBAL_TOKENIZER)
except Exception as e:
    url_tool = Tool(
        name="URLBERT_ThreatAnalyzer",
        func=lambda x, _e=str(e): f"URL ë¶„ì„ íˆ´ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {_e}",
        description="URL ì•ˆì „/ìœ„í—˜ íŒë‹¨"
    )

RAG_INDEX_DIR = os.path.join(project_root, 'security_faiss_index')
RAG_DATA_PATH = os.path.join(project_root, 'data', 'rag_dataset.jsonl')
if not os.path.exists(RAG_INDEX_DIR):
    if os.path.exists(RAG_DATA_PATH):
        print(f"ğŸ”§ RAG ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤: {RAG_DATA_PATH} -> {RAG_INDEX_DIR}")
        build_rag_index_from_jsonl(RAG_DATA_PATH, RAG_INDEX_DIR)
    else:
        print(f"âš ï¸ RAG ë°ì´í„° íŒŒì¼({RAG_DATA_PATH})ì´ ì—†ì–´ RAG ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

try:
    rag_tool = load_rag_tool(RAG_INDEX_DIR, gemini)
except Exception as e:
    print(f"âŒ RAG íˆ´ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    rag_tool = Tool(
        name="SecurityDocsQA",
        func=lambda q: "RAG íˆ´ ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        description="ë³´ì•ˆ ë¬¸ì„œ ê²€ìƒ‰ (í˜„ì¬ ë¹„í™œì„±í™”ë¨)"
    )
# 4) ìƒì„¸ URL ì„¤ëª… í”„ë¡¬í”„íŠ¸(ê¸°ì¡´ ìœ ì§€)
URL_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ URL ë³´ì•ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ í•¨ê»˜ ì œê³µëœ URL ë¶„ì„ ê²°ê³¼ ë° ì„¸ë¶€ íŠ¹ì§• ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ,
ì™œ í•´ë‹¹ URLì´ ìœ„í—˜í•˜ê±°ë‚˜ ì•ˆì „í•œì§€ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_query}

[URL-BERT 1ì°¨ ë¶„ì„ ê²°ê³¼]
{bert_result}

[ì„¸ë¶€ íŠ¹ì§• ë°ì´í„°]
{feature_details}

[ë‹µë³€ ê°€ì´ë“œ]
1. URL-BERTì˜ ìµœì¢… íŒì •(ì •ìƒ/ì•…ì„±)ì„ ë¨¼ì € ëª…í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”.
2. 'ì„¸ë¶€ íŠ¹ì§• ë°ì´í„°'ë¥¼ ê·¼ê±°ë¡œ ë“¤ì–´ ì™œ ê·¸ë ‡ê²Œ íŒë‹¨í–ˆëŠ”ì§€ 2~3ê°€ì§€ í•µì‹¬ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.
3. ì‚¬ìš©ìê°€ ì–´ë–»ê²Œ í–‰ë™í•´ì•¼ í• ì§€ ê°„ë‹¨í•œ ì¡°ì¹˜ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.
4. ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ ëŒ€í™”ì²´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

[ìµœì¢… ë‹µë³€]
"""
url_prompt = PromptTemplate.from_template(URL_PROMPT_TEMPLATE)

# 5) ë©”ëª¨ë¦¬
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# 6) íŒŒì¸íŠœë‹ëœ LLaMA ë¡œë“œ 
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch, os

BASE_ID = "MLP-KTLim/llama-3-Korean-Bllossom-8B"
LLM_DIR = os.environ.get("LLM_DIR", "models/bllossom_merged_fp16")

# âœ… ë² ì´ìŠ¤ì—ì„œ Fast í† í¬ë‚˜ì´ì € ì‚¬ìš© (tokenizer.json)
tok = AutoTokenizer.from_pretrained(BASE_ID)  # use_fast=True (ê¸°ë³¸)
if tok.pad_token is None:
    tok.add_special_tokens({'pad_token': '[PAD]'})
tok.padding_side = "left"

device_map = {"": 0} if torch.cuda.is_available() else "cpu"
llm_model = AutoModelForCausalLM.from_pretrained(
    LLM_DIR,
    torch_dtype=(torch.float16 if torch.cuda.is_available() else torch.float32),
    device_map=device_map,
)
llm_model.resize_token_embeddings(len(tok))
print(f"âœ… Merged LLM loaded from: {LLM_DIR} (tokenizer from base: {BASE_ID}, fast)")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7) í–‰ë™ ê²°ì • ìœ í‹¸(ë°˜ë³µ/í™˜ê° ë°©ì§€ í¬í•¨)
STOP_WORDS = ["\n\n", "\nAction Result", "\nAction Logic", "\nAction Reference", "assistant\n", "assistant"]
VALID_ACTIONS = {"URLBERT_ThreatAnalyzer", "SecurityDocsQA", "Chat"}
ACT_PAT = re.compile(r"Action:\s*(?P<act>[A-Za-z_]+)\s*\nAction Input:\s*(?P<input>.+)", re.S)
URL_PAT = re.compile(r'(https?://\S+|(?:[A-Za-z0-9-]+\.)+[A-Za-z]{2,}\S*)', re.I)

def _truncate_on_stops(s: str) -> str:
    cut = len(s)
    for w in STOP_WORDS:
        i = s.find(w)
        if i != -1:
            cut = min(cut, i)
    return s[:cut]

def _first_url(text: str):
    m = URL_PAT.search(text or "")
    return m.group(0) if m else None

def decide_action_with_llm(user_query: str):
    # 1) í”„ë¡¬í”„íŠ¸
    prompt = [
        {"role": "system", "content": "ë„ˆëŠ” ë³´ì•ˆ ë¶„ì„ ì±—ë´‡ì´ì•¼. ì§ˆë¬¸ì— ë§ì¶° ì˜¤ì§ ë‹¤ìŒ í˜•ì‹ë§Œ ì¶œë ¥í•´.\nAction: <URLBERT_ThreatAnalyzer|SecurityDocsQA|Chat>\nAction Input: <í…ìŠ¤íŠ¸>"},
        {"role": "user", "content": user_query}
    ]
    # 2) í† í¬ë‚˜ì´ì¦ˆ (+ attention_mask ìƒì„±)
    inputs = tok.apply_chat_template(prompt, return_tensors="pt", add_generation_prompt=True)
    inputs = inputs.to(llm_model.device)

    # 3) ìƒì„±(ê²°ì •ë¡ +ì§§ê²Œ)
    gen = llm_model.generate(
        inputs,
        max_new_tokens=48,
        do_sample=False, temperature=0.0, top_p=1.0,
        repetition_penalty=1.2,
        eos_token_id=tok.eos_token_id,
        pad_token_id=tok.pad_token_id,
    )
    raw = tok.decode(gen[0][inputs.shape[-1]:], skip_special_tokens=True)
    raw = _truncate_on_stops(raw)

    # 4) íŒŒì‹±
    m = ACT_PAT.search(raw)
    if m and m.group("act") in VALID_ACTIONS:
        action = m.group("act").strip()
        action_input = _truncate_on_stops(m.group("input").strip()).splitlines()[0].strip()
    else:
        # í´ë°±: ê·œì¹™ ê¸°ë°˜
        why_tokens = ["ì™œ", "ì´ìœ ", "ê·¼ê±°", "ìì„¸íˆ", "ì–´ë””ê°€", "ë¬´ì—‡ ë•Œë¬¸ì—", "ì„¤ëª…"]
        why = any(k in user_query for k in why_tokens)
        url = _first_url(user_query)
        if url:
            action = "SecurityDocsQA" if why else "URLBERT_ThreatAnalyzer"
            action_input = (f"{url} ìœ„í—˜ ê·¼ê±° ì„¤ëª…" if why else url)
        else:
            action = "SecurityDocsQA"
            action_input = user_query

    # URL ì•¡ì…˜ì´ë©´ ì…ë ¥ ì •ë¦¬
    if action == "URLBERT_ThreatAnalyzer":
        url = _first_url(action_input) or _first_url(user_query)
        action_input = url if url else user_query

    return action, action_input, raw  # rawëŠ” ë””ë²„ê·¸ìš©

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8) ë³´ì¡° í•¨ìˆ˜: URLBERT ê²°ê³¼ì—ì„œ íŒì • ì¶”ì •
def _infer_verdict_from_text(bert_text: str) -> str:
    t = (bert_text or "").lower()
    bad = ["malicious", "phishing", "suspicious", "ì•…ì„±", "ìœ„í—˜", "ìœ í•´"]
    good = ["benign", "legitimate", "safe", "ì •ìƒ", "ì•ˆì „"]
    if any(tok in t for tok in bad) and not any(tok in t for tok in good):
        return "ì•…ì„±"
    if any(tok in t for tok in good) and not any(tok in t for tok in bad):
        return "ì •ìƒ"
    return "ì •ìƒ"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 9) ìµœì¢… ë¼ìš°íŒ…(í•µì‹¬): LLaMAê°€ ê³ ë¥¸ Actionì„ ì‹¤í–‰
def get_chatbot_response(user_text: str) -> dict:
    text = user_text.strip()

    # â‘  LLaMAì—ê²Œ ë„êµ¬ ì„ íƒì„ ë§¡ê¸´ë‹¤
    action, action_input, raw_llm = decide_action_with_llm(text)

    # â‘¡ ì‹¤í–‰ ë¶„ê¸°
    if action == "URLBERT_ThreatAnalyzer":
        # ê°„ë‹¨ URL ë¶„ì„
        bert_result_text = url_tool.func(action_input)
        return {"answer": bert_result_text, "mode": "url_analysis_simple", "url": action_input,
                "action": action, "action_input": action_input, "raw_llm": raw_llm}

    elif action == "SecurityDocsQA":
        url_in_input = _first_url(action_input)
        if url_in_input:
            # ìƒì„¸ URL ë¶„ì„(ë‹¹ì‹ ì´ ë§Œë“  ì„¤ëª… í”„ë¡¬í”„íŠ¸ ê²½ë¡œ ì‚¬ìš©)
            bert_result_text = url_tool.func(url_in_input)
            try:
                raw_features_df = build_raw_features(url_in_input)
                if not raw_features_df.empty:
                    verdict = _infer_verdict_from_text(bert_result_text)
                    reasons = summarize_features_for_explanation(raw_features_df, verdict, top_k=3)
                    feature_details = "\n".join(f"- {r}" for r in reasons) if reasons else "ì„¸ë¶€ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                else:
                    feature_details = "ì„¸ë¶€ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            except Exception as e:
                feature_details = f"ì„¸ë¶€ íŠ¹ì§• ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

            final_prompt = url_prompt.format(
                user_query=text,
                bert_result=bert_result_text,
                feature_details=feature_details
            )
            final_answer = chat_tool.func(final_prompt)  # Geminië¡œ ìì—°ì–´ ì„¤ëª… ìƒì„±
            return {"answer": final_answer, "mode": "url_analysis_detailed", "url": url_in_input,
                    "action": action, "action_input": action_input, "raw_llm": raw_llm}
        else:
            # ì¼ë°˜ ë³´ì•ˆ ì§€ì‹/ë¬¸ì„œ ê²€ìƒ‰
            rag_out = rag_tool.func(text)
            rag_answer = rag_out.get("answer", "")
            sources = rag_out.get("sources", [])
            return {"answer": rag_answer, "mode": "rag", "sources": sources[:5],
                    "action": action, "action_input": action_input, "raw_llm": raw_llm}

    else:
        # Chat
        chat_answer = chat_tool.func(text)
        return {"answer": chat_answer, "mode": "chat",
                "action": action, "action_input": action_input, "raw_llm": raw_llm}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 10) ì¸í„°ë™í‹°ë¸Œ ë£¨í”„(í…ŒìŠ¤íŠ¸)
if __name__ == '__main__':
    print("--- ì±—ë´‡ ì‹œì‘ (ì¢…ë£Œ: 'ì¢…ë£Œ') ---")
    while True:
        try:
            text = input("You â–¶ ").strip()
        except (EOFError, KeyboardInterrupt):
            break

        if text.lower() in {"ì¢…ë£Œ", "exit"}:
            break
        if not text:
            continue

        response = get_chatbot_response(text)

        answer = response.get("answer")
        mode = response.get("mode")

        # ë©”ëª¨ë¦¬ ê¸°ë¡
        memory.save_context({"input": text}, {"output": answer})

        if mode == "rag":
            print("ğŸ” [RAG ë¬¸ì„œ ê¸°ë°˜ ì‘ë‹µ]")
        elif mode == "chat":
            print("ğŸ’¬ [ì¼ë°˜ Chat ì‘ë‹µ]")
        elif mode == "url_analysis_detailed":
            print("ğŸ”— [URL ìƒì„¸ ë¶„ì„]")
            if response.get("url"):
                print(f"   ëŒ€ìƒ: {response['url']}")
        elif mode == "url_analysis_simple":
            print("ğŸ”— [URL ê°„ë‹¨ ë¶„ì„]")
            if response.get("url"):
                print(f"   ëŒ€ìƒ: {response['url']}")

        print(f"Bot â–¶ Final Answer: {answer}")

        if response.get("sources"):
            print("ğŸ“š [ì¶œì²˜]")
            for s in response["sources"]:
                print(" -", s)

        # ë””ë²„ê¹… ì›í•˜ë©´ ì£¼ì„ í•´ì œ
        # print("[LLM raw]\n", response.get("raw_llm"))
