# bot/bot_main.py

import re
import os
import sys
import torch # LlamaCppì—ì„œ GPU ì‚¬ìš©ì„ ìœ„í•´ í•„ìš”í•  ìˆ˜ ìˆìŒ

from langchain.agents import initialize_agent, Tool
from langchain.memory import ConversationBufferMemory
from langchain_community.llms import LlamaCpp
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

# project_rootëŠ” ì´ì œ colscanì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ì§ì ‘ ì§€ì •í•©ë‹ˆë‹¤.
project_root = "/content/drive/MyDrive/sQanAR/colscan"
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# urlbert/urlbert2/ ì´ sys.path ì— ìˆì–´ì•¼ urlbert.urlbert2.core.model_loader ë“± ì„í¬íŠ¸ ê°€ëŠ¥
urlbert_base_path = os.path.join(project_root, 'urlbert', 'urlbert2')
if urlbert_base_path not in sys.path:
    sys.path.insert(0, urlbert_base_path)

# 1) URL-BERT ë¶„ì„ íˆ´
from bot.tools.urlbert_tool import load_urlbert_tool
# 2) RAG ë³´ì•ˆ ë¬¸ì„œ ê²€ìƒ‰ íˆ´ (ì¸ë±ìŠ¤ ìƒì„± í•¨ìˆ˜ í¬í•¨)
from bot.tools.rag_tools import load_rag_tool, build_rag_index_from_jsonl # â­ ì¸ë±ìŠ¤ ìƒì„± í•¨ìˆ˜ ì„í¬íŠ¸ ì¶”ê°€

def chat_tool_fn(query: str) -> str:
    return llm(query)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# GGUF ëª¨ë¸ ê²½ë¡œ
MODEL_GGUF_PATH = "/content/drive/MyDrive/sQanAR/colscan/models/gguf/llama-3-Korean-Bllossom-8B-Q4_K_M.gguf"

if not os.path.exists(MODEL_GGUF_PATH):
    print(f"âŒ ì˜¤ë¥˜: GGUF ëª¨ë¸ íŒŒì¼ì´ ë‹¤ìŒ ê²½ë¡œì— ì—†ìŠµë‹ˆë‹¤: {MODEL_GGUF_PATH}")
    print("ì´ì „ Colab ì…€ì—ì„œ GGUF ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¥¼ ë¨¼ì € ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1) # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ

print("Llama GGUF ëª¨ë¸ ë¡œë“œ ì‹œì‘...")
llm = LlamaCpp(
    model_path=MODEL_GGUF_PATH,
    n_gpu_layers=-1, # -1ì€ ê°€ëŠ¥í•œ ëª¨ë“  ë ˆì´ì–´ë¥¼ GPUì— ë¡œë“œ (GPU ë©”ëª¨ë¦¬ê°€ í—ˆìš©í•˜ëŠ” í•œ)
    n_ctx=8192,      # Llama-3ì˜ ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´
    max_tokens=1024, # ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜
    temperature=0.7, # ì°½ì˜ì„± ì¡°ì ˆ
    top_p=0.9,
    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),
    verbose=True, # ìì„¸í•œ ë¡œê·¸ ì¶œë ¥
)
print("âœ… Llama GGUF ëª¨ë¸ ë¡œë“œ ë° LangChain LLM ê°ì²´ ìƒì„± ì™„ë£Œ.")

# íˆ´ ë¡œë“œ
from urlbert.urlbert2.core.model_loader import load_inference_model as load_urlbert_inference_model
urlbert_model, urlbert_tokenizer = load_urlbert_inference_model()
url_tool = load_urlbert_tool(urlbert_model, urlbert_tokenizer)
print("âœ… URL-BERT Tool ë¡œë“œ ì™„ë£Œ.")

# RAG ì¸ë±ìŠ¤ ê²½ë¡œ ë° ìƒì„± ë¡œì§
# security_faiss_indexëŠ” colscan ë°”ë¡œ ì•„ë˜ì— ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
RAG_INDEX_PATH = os.path.join(project_root, "security_faiss_index")

# RAG ë°ì´í„° JSONL íŒŒì¼ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ëª…ì‹œí•©ë‹ˆë‹¤.
# ì‚¬ìš©ìë‹˜ì˜ ë‹µë³€ì— ë”°ë¼ rag_dataset.jsonlì€ /content/drive/MyDrive/sQanAR/colscan/data ì•ˆì— ìˆìŠµë‹ˆë‹¤.
RAG_DATA_JSONL_PATH = "/content/drive/MyDrive/sQanAR/colscan/data/rag_dataset.jsonl"


if not os.path.exists(RAG_INDEX_PATH):
    print(f"RAG ì¸ë±ìŠ¤ í´ë”ê°€ ë‹¤ìŒ ê²½ë¡œì— ì—†ìŠµë‹ˆë‹¤: {RAG_INDEX_PATH}")
    print("RAG ì¸ë±ìŠ¤ ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤...")
    if os.path.exists(RAG_DATA_JSONL_PATH):
        try:
            print(f"RAG ì¸ë±ìŠ¤ ìƒì„± ì‹œì‘ (JSONL íŒŒì¼: {RAG_DATA_JSONL_PATH})...")
            # build_rag_index_from_jsonl í•¨ìˆ˜ëŠ” ì„ë² ë”© ëª¨ë¸ë„ í•„ìš”í•©ë‹ˆë‹¤.
            # ì—¬ê¸°ì„œëŠ” LangChainì˜ ê¸°ë³¸ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ë°©ì‹ì„ ì‚¬ìš©í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
            # ë§Œì•½ íŠ¹ì • ì„ë² ë”© ëª¨ë¸ ë¡œë”©ì´ í•„ìš”í•˜ë©´ rag_tools.py ë˜ëŠ” ì—¬ê¸°ì„œ ì¶”ê°€ ë¡œì§ í•„ìš”.
            build_rag_index_from_jsonl(jsonl_path=RAG_DATA_JSONL_PATH, index_path=RAG_INDEX_PATH)
            print("âœ… RAG ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ.")
        except Exception as e:
            print(f"âŒ RAG ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("FAISS ì¸ë±ìŠ¤ ìƒì„±ì— í•„ìš”í•œ ë°ì´í„°ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            sys.exit(1)
    else:
        print(f"âŒ ì˜¤ë¥˜: RAG ë°ì´í„° JSONL íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {RAG_DATA_JSONL_PATH}")
        print("FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì±—ë´‡ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        sys.exit(1) # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ

rag_tool = load_rag_tool(RAG_INDEX_PATH, llm)
print("âœ… RAG Tool ë¡œë“œ ì™„ë£Œ.")

chat_tool = Tool(
    name="Chat",
    func=chat_tool_fn,
    description="ì¼ë°˜ ëŒ€í™” ë° ì¶”ê°€ ì •ë³´ ê²€ìƒ‰ì— ì‚¬ìš©ë˜ëŠ” íˆ´ì…ë‹ˆë‹¤. URL ë¶„ì„ì´ë‚˜ ë³´ì•ˆ ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš” ì—†ì„ ë•Œ LLM ìì²´ ë‹µë³€ìš©."
)

tools = [url_tool, rag_tool, chat_tool]

# 1) ë©”ëª¨ë¦¬(ëŒ€í™” ê¸°ë¡)
memory = ConversationBufferMemory(memory_key="chat_history")

# 2) Agent ì´ˆê¸°í™”: zero-shot tool routing
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent="zero-shot-react-description",
    verbose=True,
    memory=memory,
    handle_parsing_errors=True # íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ ì‹œ ì—ì´ì „íŠ¸ê°€ ë” ì˜ ì²˜ë¦¬í•˜ë„ë¡
)

# 3) ì¸í„°ë™í‹°ë¸Œ ì±„íŒ… í•¨ìˆ˜
def chat(query: str) -> str:
    """
    Agentê°€ ë‚´ë¶€ì ìœ¼ë¡œ:
    - URL íŒ¨í„´ ê°ì§€ â†’ URLAnalyzer í˜¸ì¶œ
    - ë³´ì•ˆ ê°œë… ì§ˆë¬¸ ê°ì§€ â†’ SecurityDocsQA í˜¸ì¶œ
    - ê·¸ ì™¸ â†’ Chat íˆ´ (LLM ì§ì ‘ ì‘ë‹µ)
    """
    try:
        response = agent.run(query)
        return response
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‚¬ìš©ìì—ê²Œ ë©”ì‹œì§€ ë°˜í™˜
        return f"âŒ ì±—ë´‡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

if __name__ == "__main__":
    print("\n--- ì±—ë´‡ í…ŒìŠ¤íŠ¸ ì‹œì‘ ---")
    print("'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ë©´ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    try:
        while True:
            q = input("You â–¶ ").strip()
            if not q:
                continue
            if q.lower() in {"quit", "exit", "ì¢…ë£Œ"}:
                print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ğŸ‘‹")
                break
            resp = chat(q)
            print("Bot â–¶", resp)
    except KeyboardInterrupt:
        print("\nì±—ë´‡ì„ ê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤. ğŸ‘‹")