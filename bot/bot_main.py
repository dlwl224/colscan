# bot/bot_main.py

import re

from langchain.agents import initialize_agent, Tool
from langchain.memory import ConversationBufferMemory


from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from langchain.llms import HuggingFacePipeline
import torch
import os    
import sys   


project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')) # sQanAR ê²½ë¡œ
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# urlbert/urlbert2/ ì´ sys.path ì— ìˆì–´ì•¼ urlbert.urlbert2.core.model_loader ë“± ì„í¬íŠ¸ ê°€ëŠ¥
urlbert_base_path = os.path.join(project_root, 'urlbert', 'urlbert2')
if urlbert_base_path not in sys.path:
    sys.path.insert(0, urlbert_base_path)


# 1) URL-BERT ë¶„ì„ íˆ´
from bot.tools.urlbert_tool import load_urlbert_tool
# 2) RAG ë³´ì•ˆ ë¬¸ì„œ ê²€ìƒ‰ íˆ´
from bot.tools.rag_tools    import load_rag_tool

def chat_tool_fn(query: str) -> str:
    return llm(query)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MODEL_DIR = "/content/drive/MyDrive/sQanAR/colscan/models/llama-3-Korean-Blossom-8B" 

print("Llama ëª¨ë¸ ë¡œë“œ ì‹œì‘...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
model     = AutoModelForCausalLM.from_pretrained(
    MODEL_DIR,
    torch_dtype=torch.float16, # Colab GPU (T4)ì— ì í•©
    device_map="auto" # ì‚¬ìš© ê°€ëŠ¥í•œ GPUì— ëª¨ë¸ ìë™ ë¶„ì‚°
)

# pad token ì„¤ì • (ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ëª¨ë‘)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token
# ëª¨ë¸ì˜ pad_token_idê°€ ì—†ì„ ê²½ìš° tokenizerì˜ pad_token_idë¡œ ì„¤ì •
if model.config.pad_token_id is None:
    model.config.pad_token_id = tokenizer.pad_token_id


# HuggingFacePipelineìœ¼ë¡œ ë˜í•‘í•˜ì—¬ LangChain LLM ê°ì²´ë¡œ ì‚¬ìš©
pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=512, # ì±—ë´‡ ì‘ë‹µ ìµœëŒ€ ê¸¸ì´
    temperature=0.2,    # ì°½ì˜ì„± ì¡°ì ˆ (ë‚®ì„ìˆ˜ë¡ ë³´ìˆ˜ì )
    do_sample=True,     # ìƒ˜í”Œë§ ë°©ì‹ ì‚¬ìš©
    top_p=0.95,         # Top-p ìƒ˜í”Œë§ (í™•ë¥  ëˆ„ì )
    pad_token_id=tokenizer.pad_token_id # íŒ¨ë”© í† í° ID ì„¤ì •
)
llm = HuggingFacePipeline(pipeline=pipe)
print("âœ… Llama ëª¨ë¸ ë¡œë“œ ë° LangChain LLM ê°ì²´ ìƒì„± ì™„ë£Œ.")

# íˆ´ ë¡œë“œ
# urlbert_tool.pyëŠ” urlbert/urlbert2/core/model_loader.pyì˜ load_inference_model()ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
# ì´ ëª¨ë¸ì€ Llamaì™€ ë³„ê°œì˜ BERT ê¸°ë°˜ ëª¨ë¸ì´ë¯€ë¡œ, ì—¬ê¸°ì„œ ë¡œë“œí•©ë‹ˆë‹¤.
from urlbert.urlbert2.core.model_loader import load_inference_model as load_urlbert_inference_model
urlbert_model, urlbert_tokenizer = load_urlbert_inference_model()
# urlbert_tool.pyì˜ load_urlbert_tool í•¨ìˆ˜ì— ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì „ë‹¬
url_tool = load_urlbert_tool(urlbert_model, urlbert_tokenizer)
print("âœ… URL-BERT Tool ë¡œë“œ ì™„ë£Œ.")

# RAGëŠ” ìƒˆë¡œ ë¡œë“œëœ Llama LLM ì‚¬ìš©
rag_tool = load_rag_tool("security_faiss_index", llm)
print("âœ… RAG Tool ë¡œë“œ ì™„ë£Œ.")

chat_tool  = Tool(
    name="Chat",
    func=chat_tool_fn,
    description="ì¼ë°˜ ëŒ€í™” ë° ì¶”ê°€ ì •ë³´ ê²€ìƒ‰ì— ì‚¬ìš©ë˜ëŠ” íˆ´ì…ë‹ˆë‹¤. URL ë¶„ì„ì´ë‚˜ ë³´ì•ˆ ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš” ì—†ì„ ë•Œ LLM ìì²´ ë‹µë³€ìš©."
)

tools = [url_tool, rag_tool, chat_tool]

# 1) ë©”ëª¨ë¦¬(ëŒ€í™” ê¸°ë¡)
memory = ConversationBufferMemory(memory_key="chat_history")

# 2) Agent ì´ˆê¸°í™”: zero-shot tool routing
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent="zero-shot-react-description",
    verbose=True,
    memory=memory,
)

# 3) ì¸í„°ë™í‹°ë¸Œ ì±„íŒ… í•¨ìˆ˜
def chat(query: str) -> str:
    """
    Agentê°€ ë‚´ë¶€ì ìœ¼ë¡œ:
    - URL íŒ¨í„´ ê°ì§€ â†’ URLAnalyzer í˜¸ì¶œ
    - ë³´ì•ˆ ê°œë… ì§ˆë¬¸ ê°ì§€ â†’ SecurityDocsQA í˜¸ì¶œ
    - ê·¸ ì™¸ â†’ Chat íˆ´ (LLM ì§ì ‘ ì‘ë‹µ)
    """
    try:
        response = agent.run(query)
        return response
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‚¬ìš©ìì—ê²Œ ë©”ì‹œì§€ ë°˜í™˜
        return f"âŒ ì±—ë´‡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

if __name__ == "__main__":
    print("\n--- ì±—ë´‡ í…ŒìŠ¤íŠ¸ ì‹œì‘ ---")
    print("'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ë©´ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    try:
        while True:
            q = input("You â–¶ ").strip()
            if not q:
                continue
            if q.lower() in {"quit", "exit", "ì¢…ë£Œ"}: # 'ì¢…ë£Œ' ì¶”ê°€
                print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ğŸ‘‹")
                break
            resp = chat(q)
            print("Bot â–¶", resp)
    except KeyboardInterrupt:
        print("\nì±—ë´‡ì„ ê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤. ğŸ‘‹")